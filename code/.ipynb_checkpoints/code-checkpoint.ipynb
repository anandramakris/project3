{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17920efd",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "We want to distinguish between those who are **willfully wrong** about history from those who are merely **uninformed**. Those in the former category are more dangerous, as since they present themselves as correct more people will follow their misinformation. The two categories can be analyzed by using the Pushshift API to take posts from two subreddits, **r/badhistory** and **r/AskHistorians**.\n",
    "\n",
    "The point of this exercise is to determine which classification model can correctly predict which posts come from which subreddit. The final model should be used by media companies (including Reddit itself) who want to combat misinformation by showing which words are associated with actively false and misleading claims."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5c0a4",
   "metadata": {},
   "source": [
    "## 1. Data Collection and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f986178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d58c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_badhistory = \"https://api.pushshift.io/reddit/search/submission?subreddit=badhistory\"\n",
    "res_badhistory = requests.get(url_badhistory)\n",
    "res_badhistory.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f37707",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh = res_badhistory.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a083a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-checking to see if \"data\" is the only key\n",
    "bh.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ce054",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Post', 'Subreddit'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ea5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in bh['data']:\n",
    "    if 'selftext' in post.keys():\n",
    "        # Had to use this website for help:\n",
    "        # https://www.geeksforgeeks.org/how-to-create-an-empty-dataframe-and-append-rows-columns-to-it-in-pandas/\n",
    "        df = df.append({'Post': post['selftext'], 'Subreddit': 'badhistory'}, ignore_index = True)\n",
    "\n",
    "# Check to make sure I have gotten the right posts\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7948efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a loop so I can get more data points\n",
    "for i in range(50):\n",
    "    before = bh['data'][-1]['created_utc']\n",
    "    url_bh = \"https://api.pushshift.io/reddit/search/submission?subreddit=badhistory&before=\" + str(before)\n",
    "    res_bh = requests.get(url_bh)\n",
    "    bh = res_bh.json()\n",
    "    \n",
    "    for post in bh['data']:\n",
    "        if 'selftext' in post.keys():\n",
    "            df = df.append({'Post': post['selftext'], 'Subreddit': 'badhistory'}, ignore_index = True)\n",
    "    \n",
    "    # Creating a timer so the requests do not come too fast\n",
    "    if i % 3 == 0:\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9decd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_askhistorians = \"https://api.pushshift.io/reddit/search/submission?subreddit=askhistorians\"\n",
    "res_askhistorians = requests.get(url_askhistorians)\n",
    "res_askhistorians.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cf042",
   "metadata": {},
   "outputs": [],
   "source": [
    "ah = res_askhistorians.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3041540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double-checking to see if \"data\" is the only key\n",
    "ah.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c64315",
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in ah['data']:\n",
    "    if 'selftext' in post.keys():\n",
    "        df = df.append({'Post': post['selftext'], 'Subreddit': 'askhistorians'}, ignore_index = True)\n",
    "\n",
    "# Check to make sure I have gotten the right posts\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a loop so I can get more data points\n",
    "for i in range(50):\n",
    "    before = ah['data'][-1]['created_utc']\n",
    "    url_ah = \"https://api.pushshift.io/reddit/search/submission?subreddit=askhistorians&before=\" + str(before)\n",
    "    res_ah = requests.get(url_ah)\n",
    "    ah = res_ah.json()\n",
    "    \n",
    "    for post in ah['data']:\n",
    "        if 'selftext' in post.keys():\n",
    "            df = df.append({'Post': post['selftext'], 'Subreddit': 'askhistorians'}, ignore_index = True)\n",
    "    \n",
    "    # Creating a timer so the requests do not come too fast\n",
    "    if i % 3 == 0:\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce24c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there are blank posts\n",
    "df['Post'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bfd502",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Post'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c544db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/history_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deb0676",
   "metadata": {},
   "source": [
    "## 2. Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def8e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatizing words for better predictions\n",
    "def lemmatize_columns(df):\n",
    "    for column in df.columns:\n",
    "        lem = wnl.lemmatize(column)\n",
    "    \n",
    "        if lem != column:\n",
    "            # If lemmatized word is already a column, add counts to total; otherwise replace column\n",
    "            if lem in df.columns:\n",
    "                df[lem] = df[lem] + df[column]\n",
    "            else:\n",
    "                df[lem] = df[column]\n",
    "\n",
    "            df.drop(columns = column, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a24bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most common non-stop words in r/AskHistorians posts\n",
    "X_askhistorians = df[df['Subreddit'] == 'askhistorians']['Post']\n",
    "cv_askhistorians = text.CountVectorizer(stop_words = text.ENGLISH_STOP_WORDS)\n",
    "Xcv_askhistorians = cv_askhistorians.fit_transform(X_askhistorians)\n",
    "Xcv_askhistorians_df = pd.DataFrame(Xcv_askhistorians.toarray(), \n",
    "                                    columns = cv_askhistorians.get_feature_names())\n",
    "Xcv_askhistorians_df = lemmatize_columns(Xcv_askhistorians_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ead69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv_askhistorians_df.sum().sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70799ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv_askhistorians_df.sum().sort_values(ascending = False).head(15).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc2244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most common non-stop words in r/badhistory posts\n",
    "X_badhistory = df[df['Subreddit'] == 'badhistory']['Post']\n",
    "cv_badhistory = text.CountVectorizer(stop_words = text.ENGLISH_STOP_WORDS)\n",
    "Xcv_badhistory = cv_badhistory.fit_transform(X_badhistory)\n",
    "Xcv_badhistory_df = pd.DataFrame(Xcv_badhistory.toarray(), \n",
    "                                    columns = cv_badhistory.get_feature_names())\n",
    "Xcv_badhistory_df = lemmatize_columns(Xcv_badhistory_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88431db",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv_badhistory_df.sum().sort_values(ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae392aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv_badhistory_df.sum().sort_values(ascending = False).head(15).plot(kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686d4a7",
   "metadata": {},
   "source": [
    "The words that appear in the top 15 in both subreddits and appear less than 10 times as much in r/badhistory as in r/AskHistorians - history, war, people, time, did, like, just, and year - will not be in my predictive model.\n",
    "\n",
    "Given that http, com, www, amp, and org appear very frequently in r/badhistory, it seems that posts with links are much more likely to appear in r/badhistory than in r/AskHistorians."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f33d02",
   "metadata": {},
   "source": [
    "## 3. Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25972609",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Post']\n",
    "y = df['Subreddit'].map({'askhistorians': 1, 'badhistory': 0})\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90965663",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8141c1e",
   "metadata": {},
   "source": [
    "55% is our baseline, so my model needs to do better than that in terms of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec99b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only including words in at least 2 posts\n",
    "cv = text.CountVectorizer(stop_words = text.ENGLISH_STOP_WORDS.union(['history', 'war', 'people', 'time', \n",
    "                                                                 'did', 'like', 'just', 'year']), \n",
    "                     min_df = 2)\n",
    "Xcv_train = cv.fit_transform(X_train)\n",
    "Xcv_test = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a318d703",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv_train_df = pd.DataFrame(Xcv_train.toarray(), columns = cv.get_feature_names())\n",
    "Xcv_test_df = pd.DataFrame(Xcv_test.toarray(), columns = cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c1cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv_train_df = lemmatize_columns(Xcv_train_df);\n",
    "Xcv_test_df = lemmatize_columns(Xcv_test_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ad6ddc",
   "metadata": {},
   "source": [
    "## 4. Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d882b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(Xcv_train_df, y_train)\n",
    "mnb.score(Xcv_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ff793",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.score(Xcv_test_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b390736",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(Xcv_train_df, y_train)\n",
    "lr.score(Xcv_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ab40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(Xcv_test_df, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9105cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(Xcv_train_df, y_train)\n",
    "rfc.score(Xcv_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f2f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.score(Xcv_test_df, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09696dc2",
   "metadata": {},
   "source": [
    "The Multinomial Naive Bayes, Logistic Regression, and Random Forest models have high scores for both the training and test sets. While Random Forest has the highest score for the training set and Logistic Regression has the highest for the test set, all three have around the same score difference, so further analysis is needed to determine which model is the best. Since all have a difference higher than 0.1 between the training and test scores, the models are likely overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9f394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_preds = mnb.predict(Xcv_test_df)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, mnb_preds).ravel()\n",
    "plot_confusion_matrix(mnb, Xcv_test_df, y_test, cmap='Reds');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3b4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity\n",
    "print(tp/(tp+fn))\n",
    "\n",
    "# Specificity\n",
    "print(tn/(tn+fp))\n",
    "\n",
    "# Precision\n",
    "print(tp/(tp+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899aaf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = lr.predict(Xcv_test_df)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, lr_preds).ravel()\n",
    "plot_confusion_matrix(lr, Xcv_test_df, y_test, cmap='Reds');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565aa2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity\n",
    "print(tp/(tp+fn))\n",
    "\n",
    "# Specificity\n",
    "print(tn/(tn+fp))\n",
    "\n",
    "# Precision\n",
    "print(tp/(tp+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f14686",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_preds = rfc.predict(Xcv_test_df)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, rfc_preds).ravel()\n",
    "plot_confusion_matrix(rfc, Xcv_test_df, y_test, cmap='Reds');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity\n",
    "print(tp/(tp+fn))\n",
    "\n",
    "# Specificity\n",
    "print(tn/(tn+fp))\n",
    "\n",
    "# Precision\n",
    "print(tp/(tp+fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc61eb8",
   "metadata": {},
   "source": [
    "The logistic regression model heavily outscores the naive Bayes model in specificity, but is worse in precision and much worse in specificity. The random forest model has both specificity and sensitivity in between those of the other two models.\n",
    "\n",
    "Since the point of this problem is to correctly identify those who are **wrong** about history, it is more important that I correctly identify those in the former category. Thus, it would be better to have higher specificity than higher sensitivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c0d94",
   "metadata": {},
   "source": [
    "Given both its high specificity and accuracy, I would argue to use the **random forest classifier** model to determine whether a post is in r/AskHistorians or r/badhistory based on its contents, and thus to determine which words are more closely associated with false and misleading information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb73961",
   "metadata": {},
   "source": [
    "As r/badhistory contains so many posts with links and link terms do not have much to do with misinformation, future research would need to show if an algorithm can clearly tell non-link posts in r/badhistory from those in r/AskHistorians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131b8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
